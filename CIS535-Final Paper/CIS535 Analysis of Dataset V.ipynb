{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 535 Analysis of Dataset \"V\"\n",
    "\n",
    "Here, we consume file `./data/v.txt` to obtain a set of 1000 observations. The dataset has an unknown origin, and goals are not specified on whether we should expect any correlations in the data.\n",
    "\n",
    "Each observation with 10 columns. The first 9 columns representing inputs, and the last column respresenting the output.\n",
    "\n",
    "We will use Tensorflow to analyze these records and create a neural network.\n",
    "\n",
    "In order to render graphs in our notebook, we need to install `matplotlib` into our tensorflow conda environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Perhaps not necessary\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data\n",
    "\n",
    "Here, we read our data from `./data/v.txt` into two separate variables: `v_inputs` and `v_output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'label']\n",
      "FEATURES ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
      "LABEL label\n"
     ]
    }
   ],
   "source": [
    "# Data sets\n",
    "V_TRAINING = \"data/v_training.csv\"\n",
    "V_TEST     = \"data/v_test.csv\"\n",
    "V_PREDICT  = \"data/v_predict.csv\"\n",
    "\n",
    "# We do not know exactly what our data represents,\n",
    "# but we do know our label is the last column.\n",
    "COLUMNS  = \"a b c d e f g h i j label\".split(\" \")\n",
    "FEATURES = COLUMNS[:-1]\n",
    "LABEL    = COLUMNS[-1]\n",
    "\n",
    "print(\"COLUMNS\", COLUMNS)\n",
    "print(\"FEATURES\", FEATURES)\n",
    "print(\"LABEL\", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "# skip header row\n",
    "training_set = pd.read_csv(V_TRAINING, skipinitialspace=True,\n",
    "                           skiprows=1, names=COLUMNS)\n",
    "test_set = pd.read_csv(V_TEST, skipinitialspace=True,\n",
    "                       skiprows=1, names=COLUMNS)\n",
    "prediction_set = pd.read_csv(V_PREDICT, skipinitialspace=True,\n",
    "                             skiprows=1, names=COLUMNS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns\n",
    "\n",
    "Now that we have our data, we will create a list of `FeatureColumn` for the input data.\n",
    "\n",
    "All of our columns consist of continuous values, so we may declare all of them using:\n",
    "\n",
    "```python\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k)\n",
    "                  for k in FEATURES]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [tf.contrib.layers.real_valued_column(k)\n",
    "                for k in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor\n",
    "\n",
    "And, we can create our regressor.\n",
    "\n",
    "> Now, instantiate a `DNNRegressor` for the neural network regression model. You'll need to provide two arguments here: `hidden_units`, a hyperparameter specifying the number of nodes in each hidden layer (here, two hidden layers with 10 nodes each), and `feature_columns`, containing the list of FeatureColumns you just defined:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0d/xlt_41kx1rl06nd42vsmm0jc0000gp/T/tmpxg5gdvrr\n",
      "WARNING:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'num_ps_replicas': 0, 'keep_checkpoint_every_n_hours': 10000, 'evaluation_master': '', 'tf_random_seed': None, '_is_chief': True, 'save_summary_steps': 100, 'master': '', 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'keep_checkpoint_max': 5, 'save_checkpoints_secs': 600, 'task': 0, '_job_name': None, 'cluster_spec': None}\n"
     ]
    }
   ],
   "source": [
    "regressor = tf.contrib.learn.DNNRegressor(\n",
    "    feature_columns=feature_cols, hidden_units=[10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function\n",
    "\n",
    "The body of the input function contains the specific logic for preprocessing your input data, such as scrubbing out bad examples or feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def input_fn(data_set):\n",
    "    # Values of feature columns\n",
    "    feature_cols = {k: tf.constant(data_set[k].values)\n",
    "                    for k in FEATURES }\n",
    "    # Return the label values of the passed data_set\n",
    "    label_tensor = tf.constant(data_set[LABEL].values)\n",
    "    \n",
    "    # Return your data split apart for the Regressor,\n",
    "    # This allows the columns to be any order, and to quickly change which\n",
    "    # columns you want to observe.\n",
    "    return feature_cols, label_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input data is passed into input_fn in the data_set argument, which means the function can process any of the DataFrames you've imported: training_set, test_set, and prediction_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting feature info to {'b': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'c': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'e': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'i': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'd': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'j': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'f': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'g': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'a': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'h': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False)}\n",
      "INFO:tensorflow:Setting targets info to TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='a', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='b', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='c', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='d', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='e', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='f', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='g', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='h', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='i', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='j', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Create CheckpointSaverHook\n",
      "INFO:tensorflow:loss = 0.427942, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/0d/xlt_41kx1rl06nd42vsmm0jc0000gp/T/tmpxg5gdvrr/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.00966336, step = 101\n",
      "INFO:tensorflow:loss = 0.00316414, step = 201\n",
      "INFO:tensorflow:loss = 0.00262626, step = 301\n",
      "INFO:tensorflow:loss = 0.00233719, step = 401\n",
      "INFO:tensorflow:loss = 0.00214159, step = 501\n",
      "INFO:tensorflow:loss = 0.00199476, step = 601\n",
      "INFO:tensorflow:loss = 0.00187944, step = 701\n",
      "INFO:tensorflow:loss = 0.0017805, step = 801\n",
      "INFO:tensorflow:loss = 0.00185619, step = 901\n",
      "INFO:tensorflow:loss = 0.00160546, step = 1001\n",
      "INFO:tensorflow:loss = 0.00151725, step = 1101\n",
      "INFO:tensorflow:loss = 0.00143484, step = 1201\n",
      "INFO:tensorflow:loss = 0.00162993, step = 1301\n",
      "INFO:tensorflow:loss = 0.00128805, step = 1401\n",
      "INFO:tensorflow:loss = 0.00121683, step = 1501\n",
      "INFO:tensorflow:loss = 0.00115352, step = 1601\n",
      "INFO:tensorflow:loss = 0.00109339, step = 1701\n",
      "INFO:tensorflow:loss = 0.00110403, step = 1801\n",
      "INFO:tensorflow:loss = 0.00100103, step = 1901\n",
      "INFO:tensorflow:loss = 0.000931313, step = 2001\n",
      "INFO:tensorflow:loss = 0.000883105, step = 2101\n",
      "INFO:tensorflow:loss = 0.00083956, step = 2201\n",
      "INFO:tensorflow:loss = 0.000802287, step = 2301\n",
      "INFO:tensorflow:loss = 0.00104574, step = 2401\n",
      "INFO:tensorflow:loss = 0.000730538, step = 2501\n",
      "INFO:tensorflow:loss = 0.000698634, step = 2601\n",
      "INFO:tensorflow:loss = 0.000671801, step = 2701\n",
      "INFO:tensorflow:loss = 0.000647397, step = 2801\n",
      "INFO:tensorflow:loss = 0.000626018, step = 2901\n",
      "INFO:tensorflow:loss = 0.000622032, step = 3001\n",
      "INFO:tensorflow:loss = 0.000694451, step = 3101\n",
      "INFO:tensorflow:loss = 0.000579002, step = 3201\n",
      "INFO:tensorflow:loss = 0.000561066, step = 3301\n",
      "INFO:tensorflow:loss = 0.000548088, step = 3401\n",
      "INFO:tensorflow:loss = 0.000537197, step = 3501\n",
      "INFO:tensorflow:loss = 0.000527606, step = 3601\n",
      "INFO:tensorflow:loss = 0.000519025, step = 3701\n",
      "INFO:tensorflow:loss = 0.000510714, step = 3801\n",
      "INFO:tensorflow:loss = 0.000505358, step = 3901\n",
      "INFO:tensorflow:loss = 0.000539739, step = 4001\n",
      "INFO:tensorflow:loss = 0.000528516, step = 4101\n",
      "INFO:tensorflow:loss = 0.000486632, step = 4201\n",
      "INFO:tensorflow:loss = 0.000479686, step = 4301\n",
      "INFO:tensorflow:loss = 0.000474547, step = 4401\n",
      "INFO:tensorflow:loss = 0.000469927, step = 4501\n",
      "INFO:tensorflow:loss = 0.000465393, step = 4601\n",
      "INFO:tensorflow:loss = 0.000461246, step = 4701\n",
      "INFO:tensorflow:loss = 0.000472301, step = 4801\n",
      "INFO:tensorflow:loss = 0.000520948, step = 4901\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/0d/xlt_41kx1rl06nd42vsmm0jc0000gp/T/tmpxg5gdvrr/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.000457958.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(dropout=None, feature_columns=[_RealValuedColumn(column_name='a', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='b', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='c', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='d', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='e', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='f', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='g', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='h', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='i', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='j', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], optimizer=None, hidden_units=[10, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "> Next, see how the trained model performs against the test data set. Run evaluate, and this time pass the test_set to the input_fn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Given features: {'b': <tf.Tensor 'Const_1:0' shape=(100,) dtype=float64>, 'c': <tf.Tensor 'Const_2:0' shape=(100,) dtype=float64>, 'f': <tf.Tensor 'Const_5:0' shape=(100,) dtype=float64>, 'd': <tf.Tensor 'Const_3:0' shape=(100,) dtype=float64>, 'j': <tf.Tensor 'Const_9:0' shape=(100,) dtype=float64>, 'i': <tf.Tensor 'Const_8:0' shape=(100,) dtype=float64>, 'e': <tf.Tensor 'Const_4:0' shape=(100,) dtype=float64>, 'g': <tf.Tensor 'Const_6:0' shape=(100,) dtype=float64>, 'a': <tf.Tensor 'Const:0' shape=(100,) dtype=float64>, 'h': <tf.Tensor 'Const_7:0' shape=(100,) dtype=float64>}, required signatures: {'b': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'c': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'e': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'i': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'd': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'j': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'f': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'g': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'a': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False), 'h': TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False)}.\n",
      "WARNING:tensorflow:Given targets: Tensor(\"Const_10:0\", shape=(100,), dtype=float64), required signatures: TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(900)]), is_sparse=False).\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='a', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='b', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='c', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='d', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='e', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='f', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='g', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='h', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='i', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='j', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Restored model from /var/folders/0d/xlt_41kx1rl06nd42vsmm0jc0000gp/T/tmpxg5gdvrr\n",
      "INFO:tensorflow:Eval steps [0,1) for training step 5000.\n",
      "INFO:tensorflow:Saving evaluation summary for 5000 step: loss = 0.00104085\n"
     ]
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have created an evaluation, we can output a loss score from our `ev` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.001041\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "So, now that we have trained and evaluated our model, we can start to try making predictions with it!\n",
    "\n",
    "We can use `regressor.predict` to only read from the feature columns, and forecast the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='a', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='b', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='c', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='d', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='e', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='f', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='g', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='h', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='i', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='j', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Loading model from checkpoint: /var/folders/0d/xlt_41kx1rl06nd42vsmm0jc0000gp/T/tmpxg5gdvrr/model.ckpt-5000-?????-of-00001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [-0.03536016 -0.49997067 -0.0100856  -0.42367306 -0.36693686]\n"
     ]
    }
   ],
   "source": [
    "y = regressor.predict(input_fn=lambda: input_fn(prediction_set), as_iterable=False)\n",
    "\n",
    "print(\"Predictions: {}\".format(str(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "# first 9 columns\n",
    "f = open('data/v.txt', 'r')\n",
    "lns = f.readlines()\n",
    "\n",
    "# Create a 2D array of the rows, and values\n",
    "v_data = [ [ float(f)\n",
    "        for f in l.split('\\t') ]\n",
    "            for l in lns ]\n",
    "\n",
    "v_inputs = [record[0:10] for record in v_data]\n",
    "v_output = [record[10] for record in v_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Let us start building our neural network with a model\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a linear model\n",
    "pred = tf.add(tf.mul(X, W), b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#self.name = f.readline().rstrip()\n",
    "#self.age = int(f.readline())\n",
    "#self.height = float(f.readline())\n",
    "#self.weight = int(f.readline())\n",
    "\n",
    "# this input is of the 2D shape [any length], [9]\n",
    "rX = tf.placeholder(tf.float32, [None, 9])\n",
    "rY = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7    2.76   2.09   3.19   1.694  1.573  3.366  2.596  2.53   1.221\n",
      "  2.827  3.465  1.65   2.904  2.42   2.94   1.3  ]\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(train_Y)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "INFO:tensorflow:Using config: {'num_ps_replicas': 0, 'keep_checkpoint_every_n_hours': 10000, 'evaluation_master': '', 'tf_random_seed': None, '_is_chief': True, 'save_summary_steps': 100, 'master': '', 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'keep_checkpoint_max': 5, 'save_checkpoints_secs': 1, 'task': 0, '_job_name': None, 'cluster_spec': None}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Setting feature info to TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "INFO:tensorflow:Setting targets info to TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=10, default_value=None, dtype=tf.float32, normalizer=None)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataType float64 for attr 'Tlabels' not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a04c3bebd9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                monitors=[validation_monitor])\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Evaluate accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    433\u001b[0m     result = self._estimator.fit(x=x, y=y, input_fn=input_fn, steps=steps,\n\u001b[1;32m    434\u001b[0m                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                                  max_steps=max_steps)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmonitors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    331\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                              \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m                              max_steps=max_steps)\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m       \u001b[0;31m# Add default monitors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0mTuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \"\"\"\n\u001b[0;32m--> 963\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, targets, mode)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'mode'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'params'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\u001b[0m in \u001b[0;36m_dnn_classifier_model_fn\u001b[0;34m(features, targets, mode, params)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     loss = loss_fn(logits, targets,\n\u001b[0;32m--> 258\u001b[0;31m                    weight=_get_weight_tensor(features, weight_column_name))\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     train_ops = [optimizers.optimize_loss(\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy\u001b[0;34m(logits, labels, weight, scope)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     losses = nn.sparse_softmax_cross_entropy_with_logits(logits, labels,\n\u001b[0;32m--> 417\u001b[0;31m                                                          name=\"xentropy\")\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_weighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(logits, labels, name)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       cost, _ = gen_nn_ops._sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m--> 764\u001b[0;31m           precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m    765\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m_sparse_softmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m   1855\u001b[0m   \"\"\"\n\u001b[1;32m   1856\u001b[0m   result = _op_def_lib.apply_op(\"SparseSoftmaxCrossEntropyWithLogits\",\n\u001b[0;32m-> 1857\u001b[0;31m                                 features=features, labels=labels, name=name)\n\u001b[0m\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseSoftmaxCrossEntropyWithLogitsOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m--> 573\u001b[0;31m                                        _Attr(op_def, input_arg.type_attr))\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/colelawrence/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"DataType %s for attr '%s' not in list of allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (dtypes.as_dtype(dtype).name, attr_def.name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: DataType float64 for attr 'Tlabels' not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "\"\"\"Model training for Iris data set using Validation Monitor.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Data sets\n",
    "V_TRAINING = \"data/v_training.csv\"\n",
    "V_TEST = \"data/v_test.csv\"\n",
    "\n",
    "# Load datasets.\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=V_TRAINING, target_dtype=np.float, features_dtype=np.float)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=V_TEST, target_dtype=np.float, features_dtype=np.float)\n",
    "\n",
    "validation_metrics = {\n",
    "    \"accuracy\": MetricSpec(\n",
    "                        metric_fn=tf.contrib.metrics.streaming_accuracy,\n",
    "                        prediction_key=\"classes\"),\n",
    "    \"recall\": MetricSpec(\n",
    "                        metric_fn=tf.contrib.metrics.streaming_recall,\n",
    "                        prediction_key=\"classes\"),\n",
    "    \"precision\": MetricSpec(\n",
    "                        metric_fn=tf.contrib.metrics.streaming_precision,\n",
    "                        prediction_key=\"classes\")\n",
    "                      }\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    test_set.data,\n",
    "    test_set.target,\n",
    "    every_n_steps=50,\n",
    "    metrics=validation_metrics,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=200)\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "estimator = tf.contrib.learn.DNNRegressor(feature_columns=feature_columns,\n",
    "                                          hidden_units=[10, 20, 10],\n",
    "                                          n_classes=3,\n",
    "                                          model_dir=\"/tmp/v_model\",\n",
    "                                          config=tf.contrib.learn.RunConfig(\n",
    "                                              save_checkpoints_secs=1))\n",
    "\n",
    "# Fit model.\n",
    "estimator.fit(x=training_set.data,\n",
    "               y=training_set.target,\n",
    "               steps=2000,\n",
    "               monitors=[validation_monitor])\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = estimator.evaluate(x=test_set.data,\n",
    "                                     y=test_set.target)[\"accuracy\"]\n",
    "print(\"Accuracy: {0:f}\".format(accuracy_score))\n",
    "\n",
    "# Classify two new flower samples.\n",
    "new_samples = np.array(\n",
    "    [[0.865874708,0.820106596,0.150704431,0.627245984,0.19453678,0.913716318,0.569297894,0.643728125,0.275551608,0.649479039],\n",
    "     # expecting 0.177251929\n",
    "     [0.343617366,0.140894357,0.9011357,0.416433035,0.714652943,0.953001468,0.2806044,0.538037583,0.123400512,0.181083975]\n",
    "     # expecting -0.633059251\n",
    "    ], dtype=float)\n",
    "\n",
    "y = list(estimator.predict(new_samples, as_iterable=True))\n",
    "print(\"Predictions: {}\".format(str(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
